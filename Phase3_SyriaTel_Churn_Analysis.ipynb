{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SyriaTel Customer Churn Prediction - Phase 3 Project\n",
    "\n",
    "## Business Problem\n",
    "\n",
    "**Objective**: Build a classifier to predict whether SyriaTel customers will \"soon\" stop doing business with the company.\n",
    "\n",
    "**Problem Type**: Binary Classification\n",
    "- Target variable: Customer churn (True/False)\n",
    "- Audience: SyriaTel business stakeholders interested in reducing revenue loss\n",
    "\n",
    "**Business Context**: \n",
    "- Customer acquisition costs are high in telecommunications\n",
    "- Retaining existing customers is more cost-effective\n",
    "- Early identification of at-risk customers enables proactive retention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>account length</th>\n",
       "      <th>area code</th>\n",
       "      <th>phone number</th>\n",
       "      <th>international plan</th>\n",
       "      <th>voice mail plan</th>\n",
       "      <th>number vmail messages</th>\n",
       "      <th>total day minutes</th>\n",
       "      <th>total day calls</th>\n",
       "      <th>total day charge</th>\n",
       "      <th>...</th>\n",
       "      <th>total eve calls</th>\n",
       "      <th>total eve charge</th>\n",
       "      <th>total night minutes</th>\n",
       "      <th>total night calls</th>\n",
       "      <th>total night charge</th>\n",
       "      <th>total intl minutes</th>\n",
       "      <th>total intl calls</th>\n",
       "      <th>total intl charge</th>\n",
       "      <th>customer service calls</th>\n",
       "      <th>churn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KS</td>\n",
       "      <td>128</td>\n",
       "      <td>415</td>\n",
       "      <td>382-4657</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>25</td>\n",
       "      <td>265.1</td>\n",
       "      <td>110</td>\n",
       "      <td>45.07</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>16.78</td>\n",
       "      <td>244.7</td>\n",
       "      <td>91</td>\n",
       "      <td>11.01</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OH</td>\n",
       "      <td>107</td>\n",
       "      <td>415</td>\n",
       "      <td>371-7191</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>26</td>\n",
       "      <td>161.6</td>\n",
       "      <td>123</td>\n",
       "      <td>27.47</td>\n",
       "      <td>...</td>\n",
       "      <td>103</td>\n",
       "      <td>16.62</td>\n",
       "      <td>254.4</td>\n",
       "      <td>103</td>\n",
       "      <td>11.45</td>\n",
       "      <td>13.7</td>\n",
       "      <td>3</td>\n",
       "      <td>3.70</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NJ</td>\n",
       "      <td>137</td>\n",
       "      <td>415</td>\n",
       "      <td>358-1921</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>243.4</td>\n",
       "      <td>114</td>\n",
       "      <td>41.38</td>\n",
       "      <td>...</td>\n",
       "      <td>110</td>\n",
       "      <td>10.30</td>\n",
       "      <td>162.6</td>\n",
       "      <td>104</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.2</td>\n",
       "      <td>5</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OH</td>\n",
       "      <td>84</td>\n",
       "      <td>408</td>\n",
       "      <td>375-9999</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>299.4</td>\n",
       "      <td>71</td>\n",
       "      <td>50.90</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>5.26</td>\n",
       "      <td>196.9</td>\n",
       "      <td>89</td>\n",
       "      <td>8.86</td>\n",
       "      <td>6.6</td>\n",
       "      <td>7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OK</td>\n",
       "      <td>75</td>\n",
       "      <td>415</td>\n",
       "      <td>330-6626</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>166.7</td>\n",
       "      <td>113</td>\n",
       "      <td>28.34</td>\n",
       "      <td>...</td>\n",
       "      <td>122</td>\n",
       "      <td>12.61</td>\n",
       "      <td>186.9</td>\n",
       "      <td>121</td>\n",
       "      <td>8.41</td>\n",
       "      <td>10.1</td>\n",
       "      <td>3</td>\n",
       "      <td>2.73</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state  account length  area code phone number international plan  \\\n",
       "0    KS             128        415     382-4657                 no   \n",
       "1    OH             107        415     371-7191                 no   \n",
       "2    NJ             137        415     358-1921                 no   \n",
       "3    OH              84        408     375-9999                yes   \n",
       "4    OK              75        415     330-6626                yes   \n",
       "\n",
       "  voice mail plan  number vmail messages  total day minutes  total day calls  \\\n",
       "0             yes                     25              265.1              110   \n",
       "1             yes                     26              161.6              123   \n",
       "2              no                      0              243.4              114   \n",
       "3              no                      0              299.4               71   \n",
       "4              no                      0              166.7              113   \n",
       "\n",
       "   total day charge  ...  total eve calls  total eve charge  \\\n",
       "0             45.07  ...               99             16.78   \n",
       "1             27.47  ...              103             16.62   \n",
       "2             41.38  ...              110             10.30   \n",
       "3             50.90  ...               88              5.26   \n",
       "4             28.34  ...              122             12.61   \n",
       "\n",
       "   total night minutes  total night calls  total night charge  \\\n",
       "0                244.7                 91               11.01   \n",
       "1                254.4                103               11.45   \n",
       "2                162.6                104                7.32   \n",
       "3                196.9                 89                8.86   \n",
       "4                186.9                121                8.41   \n",
       "\n",
       "   total intl minutes  total intl calls  total intl charge  \\\n",
       "0                10.0                 3               2.70   \n",
       "1                13.7                 3               3.70   \n",
       "2                12.2                 5               3.29   \n",
       "3                 6.6                 7               1.78   \n",
       "4                10.1                 3               2.73   \n",
       "\n",
       "   customer service calls  churn  \n",
       "0                       1  False  \n",
       "1                       1  False  \n",
       "2                       0  False  \n",
       "3                       2  False  \n",
       "4                       3  False  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score, \n",
    "                           roc_auc_score, confusion_matrix, classification_report)\n",
    "\n",
    "df = pd.read_csv('bigml_data.csv')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target Variable Analysis:\n",
      "Churn distribution: {False: 2850, True: 483}\n",
      "Churn rate: 14.5% (483 churned out of 3333 total)\n",
      "\n",
      "Missing values per column:\n",
      "No missing values\n"
     ]
    }
   ],
   "source": [
    "print(\"Target Variable Analysis:\")\n",
    "print(f\"Churn distribution: {df['churn'].value_counts().to_dict()}\")\n",
    "\n",
    " \n",
    "df['churn'] = df['churn'].astype(str).map({'True': 1, 'False': 0})\n",
    "churn_rate = df['churn'].mean()\n",
    "print(f\"Churn rate: {churn_rate:.1%} ({df['churn'].sum()} churned out of {len(df)} total)\")\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values per column:\")\n",
    "missing_values = df.isnull().sum()\n",
    "print(missing_values[missing_values > 0] if missing_values.sum() > 0 else \"No missing values\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoded state: 51 unique values\n",
      "Encoded international plan: 2 unique values\n",
      "Encoded voice mail plan: 2 unique values\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['state',\n",
       " 'account length',\n",
       " 'area code',\n",
       " 'international plan',\n",
       " 'voice mail plan',\n",
       " 'number vmail messages',\n",
       " 'total day minutes',\n",
       " 'total day calls',\n",
       " 'total day charge',\n",
       " 'total eve minutes',\n",
       " 'total eve calls',\n",
       " 'total eve charge',\n",
       " 'total night minutes',\n",
       " 'total night calls',\n",
       " 'total night charge',\n",
       " 'total intl minutes',\n",
       " 'total intl calls',\n",
       " 'total intl charge',\n",
       " 'customer service calls']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "# cleanning of the  data unnecessary columns\n",
    "df = df.drop(columns=['phone number'], errors='ignore')\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = ['state', 'international plan', 'voice mail plan']\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_columns:\n",
    "    if col in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le\n",
    "        print(f\"Encoded {col}: {len(le.classes_)} unique values\")\n",
    "\n",
    "# features and target\n",
    "X = df.drop('churn', axis=1)\n",
    "y = df['churn']\n",
    "\n",
    "X.shape[0] \n",
    "X.shape[1]\n",
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Split:\n",
      "Training set: 2666 samples (14.5% churn rate)\n",
      "Test set: 667 samples (14.5% churn rate)\n",
      "Stratification maintained class balance âœ“\n"
     ]
    }
   ],
   "source": [
    "# Train-test split with stratification (important for classification)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Data Split:\")\n",
    "print(f\"Training set: {len(X_train)} samples ({y_train.mean():.1%} churn rate)\")\n",
    "print(f\"Test set: {len(X_test)} samples ({y_test.mean():.1%} churn rate)\")\n",
    "print(f\"Stratification maintained class balance âœ“\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterative Modeling Approach\n",
    "\n",
    "Following Phase 3 requirements, I will build multiple models iteratively:\n",
    "1. **Baseline Model**: Simple, interpretable logistic regression\n",
    "2. **Tuned Model**: Hyperparameter-optimized version of baseline\n",
    "3. **Alternative Model**: Different algorithm for comparison\n",
    "\n",
    "Each iteration includes justification for the approach and evaluation on both training and testing data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions for Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_model(name, model, X_train, X_test, y_train, y_test, use_scaling=False):\n",
    "    if use_scaling:\n",
    "        scaler = StandardScaler()\n",
    "        X_train_eval = scaler.fit_transform(X_train)\n",
    "        X_test_eval = scaler.transform(X_test)\n",
    "    else:\n",
    "        X_train_eval, X_test_eval = X_train, X_test\n",
    "    \n",
    "    # Train model\n",
    "    model.fit(X_train_eval, y_train)\n",
    "    \n",
    "    # Training predictions (to check for overfitting)\n",
    "    y_train_pred = model.predict(X_train_eval)\n",
    "    y_train_proba = model.predict_proba(X_train_eval)[:, 1]\n",
    "    \n",
    "    #  predictions\n",
    "    y_test_pred = model.predict(X_test_eval)\n",
    "    y_test_proba = model.predict_proba(X_test_eval)[:, 1]\n",
    "    \n",
    "   \n",
    "    metrics = {\n",
    "        'train_accuracy': accuracy_score(y_train, y_train_pred),\n",
    "        'test_accuracy': accuracy_score(y_test, y_test_pred),\n",
    "        'train_auc': roc_auc_score(y_train, y_train_proba),\n",
    "        'test_auc': roc_auc_score(y_test, y_test_proba),\n",
    "        'precision': precision_score(y_test, y_test_pred),\n",
    "        'recall': recall_score(y_test, y_test_pred),\n",
    "        'f1_score': f1_score(y_test, y_test_pred),\n",
    "        'confusion_matrix': confusion_matrix(y_test, y_test_pred)\n",
    "    }\n",
    "    \n",
    "    return metrics, model\n",
    "\n",
    "def print_model_evaluation(name, metrics):\n",
    "    print(f\"\\n{name} - Classification Results:\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Primary classification metrics\n",
    "    print(f\"Training AUC:   {metrics['train_auc']:.4f}\")\n",
    "    print(f\"Testing AUC:    {metrics['test_auc']:.4f}\")\n",
    "    print(f\"Accuracy:       {metrics['test_accuracy']:.4f}\")\n",
    "    print(f\"Precision:      {metrics['precision']:.4f}\")\n",
    "    print(f\"Recall:         {metrics['recall']:.4f}\")\n",
    "    print(f\"F1-Score:       {metrics['f1_score']:.4f}\")\n",
    "    \n",
    "    # Check for overfitting\n",
    "    auc_diff = metrics['train_auc'] - metrics['test_auc']\n",
    "    if auc_diff > 0.05:\n",
    "        print(f\"Potential overfitting (AUC difference: {auc_diff:.4f})\")\n",
    "    \n",
    "    # Business interpretation of confusion matrix\n",
    "    cm = metrics['confusion_matrix']\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    print(f\"\\nBusiness Impact:\")\n",
    "    print(f\"- True Positives:  {tp} (churns correctly identified)\")\n",
    "    print(f\"- False Negatives: {fn} (churns missed - revenue lost)\")\n",
    "    print(f\"- False Positives: {fp} (false alarms - wasted retention costs)\")\n",
    "    print(f\"- True Negatives:  {tn} (loyal customers correctly identified)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1: Baseline Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL 1: BASELINE LOGISTIC REGRESSION\n",
      "Justification: Simple, interpretable model good for binary classification\n",
      "This serves as our baseline to compare against\n",
      "\n",
      "Baseline Logistic Regression - Classification Results:\n",
      "--------------------------------------------------\n",
      "Training AUC:   0.8252\n",
      "Testing AUC:    0.8166\n",
      "Accuracy:       0.8591\n",
      "Precision:      0.5349\n",
      "Recall:         0.2371\n",
      "F1-Score:       0.3286\n",
      "\n",
      "Business Impact:\n",
      "- True Positives:  23 (churns correctly identified)\n",
      "- False Negatives: 74 (churns missed - revenue lost)\n",
      "- False Positives: 20 (false alarms - wasted retention costs)\n",
      "- True Negatives:  550 (loyal customers correctly identified)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"MODEL 1: BASELINE LOGISTIC REGRESSION\")\n",
    "\n",
    "\n",
    "print(\"Justification: Simple, interpretable model good for binary classification\")\n",
    "print(\"This serves as our baseline to compare against\")\n",
    "\n",
    "\n",
    "lr_baseline = LogisticRegression(random_state=42, max_iter=1000)\n",
    "metrics_baseline, model_baseline = evaluate_classification_model(\n",
    "    \"Baseline Logistic Regression\", lr_baseline, \n",
    "    X_train, X_test, y_train, y_test, use_scaling=True\n",
    ")\n",
    "\n",
    "\n",
    "print_model_evaluation(\"Baseline Logistic Regression\", metrics_baseline)\n",
    "\n",
    "\n",
    "results = {'Baseline_LR': metrics_baseline}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Baseline Model Analysis**: \n",
    "The baseline logistic regression provides a conservative approach with good precision but low recall. This means it's accurate when it predicts churn, but misses many actual churning customers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 2: Hyperparameter-Tuned Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL 2: TUNED LOGISTIC REGRESSION\n",
      "============================================================\n",
      "Justification: Improve baseline through systematic hyperparameter optimization\n",
      "Testing different regularization and class balancing strategies\n",
      "Best hyperparameters found: {'C': 0.1, 'class_weight': 'balanced', 'solver': 'liblinear'}\n",
      "Cross-validation AUC: 0.8179\n",
      "Hyperparameter tuning completed using 5-fold cross-validation\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL 2: TUNED LOGISTIC REGRESSION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Justification: Improve baseline through systematic hyperparameter optimization\")\n",
    "print(\"Testing different regularization and class balancing strategies\")\n",
    "\n",
    "# Define hyperparameter grid\n",
    "param_grid = {\n",
    "    'C': [0.1, 1.0, 10.0],  # Regularization strength\n",
    "    'class_weight': [None, 'balanced'],  # Handle class imbalance\n",
    "    'solver': ['liblinear', 'lbfgs']  # Optimization algorithms\n",
    "}\n",
    "\n",
    "# Prepare scaled data for grid search\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "lr_grid = GridSearchCV(\n",
    "    LogisticRegression(random_state=42, max_iter=1000),\n",
    "    param_grid, cv=5, scoring='roc_auc', n_jobs=-1\n",
    ")\n",
    "lr_grid.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best hyperparameters found: {lr_grid.best_params_}\")\n",
    "print(f\"Cross-validation AUC: {lr_grid.best_score_:.4f}\")\n",
    "print(f\"Hyperparameter tuning completed using 5-fold cross-validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tuned Logistic Regression - Classification Results:\n",
      "--------------------------------------------------\n",
      "Training AUC:   0.8280\n",
      "Testing AUC:    0.8163\n",
      "Accuracy:       0.7616\n",
      "Precision:      0.3510\n",
      "Recall:         0.7526\n",
      "F1-Score:       0.4787\n",
      "\n",
      "Business Impact:\n",
      "- True Positives:  73 (churns correctly identified)\n",
      "- False Negatives: 24 (churns missed - revenue lost)\n",
      "- False Positives: 135 (false alarms - wasted retention costs)\n",
      "- True Negatives:  435 (loyal customers correctly identified)\n"
     ]
    }
   ],
   "source": [
    "# Evaluate tuned model on test data\n",
    "y_test_pred_tuned = lr_grid.predict(X_test_scaled)\n",
    "y_test_proba_tuned = lr_grid.predict_proba(X_test_scaled)[:, 1]\n",
    "y_train_pred_tuned = lr_grid.predict(X_train_scaled)\n",
    "y_train_proba_tuned = lr_grid.predict_proba(X_train_scaled)[:, 1]\n",
    "\n",
    "# Calculate comprehensive metrics\n",
    "metrics_tuned = {\n",
    "    'train_accuracy': accuracy_score(y_train, y_train_pred_tuned),\n",
    "    'test_accuracy': accuracy_score(y_test, y_test_pred_tuned),\n",
    "    'train_auc': roc_auc_score(y_train, y_train_proba_tuned),\n",
    "    'test_auc': roc_auc_score(y_test, y_test_proba_tuned),\n",
    "    'precision': precision_score(y_test, y_test_pred_tuned),\n",
    "    'recall': recall_score(y_test, y_test_pred_tuned),\n",
    "    'f1_score': f1_score(y_test, y_test_pred_tuned),\n",
    "    'confusion_matrix': confusion_matrix(y_test, y_test_pred_tuned)\n",
    "}\n",
    "\n",
    "print_model_evaluation(\"Tuned Logistic Regression\", metrics_tuned)\n",
    "results['Tuned_LR'] = metrics_tuned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tuned Model Analysis**: \n",
    "Hyperparameter tuning with class balancing significantly improved recall (ability to catch churning customers) but reduced precision (more false alarms). This represents the classic precision-recall trade-off in classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 3: Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "MODEL 3: DECISION TREE CLASSIFIER\n",
      "============================================================\n",
      "Justification: Alternative interpretable model that handles non-linear relationships\n",
      "Comparing tree-based vs linear approach for this classification problem\n",
      "\n",
      "Decision Tree - Classification Results:\n",
      "--------------------------------------------------\n",
      "Training AUC:   0.9306\n",
      "Testing AUC:    0.8049\n",
      "Accuracy:       0.9055\n",
      "Precision:      0.6604\n",
      "Recall:         0.7216\n",
      "F1-Score:       0.6897\n",
      "Potential overfitting (AUC difference: 0.1257)\n",
      "\n",
      "Business Impact:\n",
      "- True Positives:  70 (churns correctly identified)\n",
      "- False Negatives: 27 (churns missed - revenue lost)\n",
      "- False Positives: 36 (false alarms - wasted retention costs)\n",
      "- True Negatives:  534 (loyal customers correctly identified)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"MODEL 3: DECISION TREE CLASSIFIER\")\n",
    "print(\"=\" * 60)\n",
    "print(\"Justification: Alternative interpretable model that handles non-linear relationships\")\n",
    "print(\"Comparing tree-based vs linear approach for this classification problem\")\n",
    "\n",
    "# Create decision tree with controls to prevent overfitting\n",
    "dt = DecisionTreeClassifier(\n",
    "    random_state=42, \n",
    "    max_depth=5,  # Limit depth to prevent overfitting\n",
    "    class_weight='balanced'  # Handle class imbalance\n",
    ")\n",
    "\n",
    "metrics_dt, model_dt = evaluate_classification_model(\n",
    "    \"Decision Tree\", dt, \n",
    "    X_train, X_test, y_train, y_test, use_scaling=False\n",
    ")\n",
    "\n",
    "print_model_evaluation(\"Decision Tree\", metrics_dt)\n",
    "results['Decision_Tree'] = metrics_dt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree Analysis**: \n",
    "The decision tree shows signs of overfitting despite depth constraints (large gap between training and test AUC). However, it achieves good recall and provides a different perspective on the classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison and Final Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODEL COMPARISON\n",
      "Model Performance Summary  by Test AUC:\n",
      "        Model  Test_AUC  Precision  Recall  F1_Score  Accuracy  Train_AUC  Overfitting\n",
      "  Baseline LR    0.8166     0.5349  0.2371    0.3286    0.8591     0.8252       0.0086\n",
      "     Tuned LR    0.8163     0.3510  0.7526    0.4787    0.7616     0.8280       0.0117\n",
      "Decision Tree    0.8049     0.6604  0.7216    0.6897    0.9055     0.9306       0.1257\n",
      "\n",
      " FINAL MODEL SELECTED: Baseline LR\n",
      "Selected based on highest test AUC score: 0.8166\n",
      "overfitting score: 0.0086\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"MODEL COMPARISON\")\n",
    "\n",
    "\n",
    "# Create comparison table\n",
    "comparison_data = []\n",
    "for name, metrics in results.items():\n",
    "    comparison_data.append({\n",
    "        'Model': name.replace('_', ' '),\n",
    "        'Test_AUC': metrics['test_auc'],\n",
    "        'Precision': metrics['precision'],\n",
    "        'Recall': metrics['recall'],\n",
    "        'F1_Score': metrics['f1_score'],\n",
    "        'Accuracy': metrics['test_accuracy'],\n",
    "        'Train_AUC': metrics['train_auc'],\n",
    "        'Overfitting': metrics['train_auc'] - metrics['test_auc']\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.sort_values('Test_AUC', ascending=False)\n",
    "\n",
    "print(\"Model Performance Summary  by Test AUC:\")\n",
    "print(comparison_df.round(4).to_string(index=False))\n",
    "\n",
    "best_model = comparison_df.iloc[0]\n",
    "print(f\"\\n FINAL MODEL SELECTED: {best_model['Model']}\")\n",
    "print(f\"Selected based on highest test AUC score: {best_model['Test_AUC']:.4f}\")\n",
    "print(f\"overfitting score: {best_model['Overfitting']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Result\n",
    "\n",
    "After systematically building and evaluating multiple models, the **Baseline Logistic Regression**  is the optimal choice for this business problem.\n",
    "\n",
    " 81.7% AUC score\n",
    " 53.5% precision\n",
    " minimal overfitting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
